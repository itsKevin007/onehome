<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<title>OpenCV: FAST Algorithm for Corner Detection</title>
<link href="../../opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../tutorial-utils.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript">
window.MathJax = {
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
  loader: {
    load: ['[tex]/ams']
  },
  tex: {
    macros: {},
    packages: ['base','configmacros','ams']
  }
};
//<![CDATA[
window.MathJax = {
    loader: {load: ['[tex]/ams']},
    tex: {
        packages: {'[+]': ['ams']},
        macros: {
            matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
            fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
            forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
            forkfour: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ #7 & \\mbox{#8}\\\\ \\end{array} \\right.", 8],
            vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
            vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
            cameramatrix: ["#1 = \\begin{bmatrix} f_x & 0 & c_x\\\\ 0 & f_y & c_y\\\\ 0 & 0 & 1 \\end{bmatrix}", 1],
            distcoeffs: ["(k_1, k_2, p_1, p_2[, k_3[, k_4, k_5, k_6 [, s_1, s_2, s_3, s_4[, \\tau_x, \\tau_y]]]]) \\text{ of 4, 5, 8, 12 or 14 elements}"],
            distcoeffsfisheye: ["(k_1, k_2, k_3, k_4)"],
            hdotsfor: ["\\dots", 1],
            mathbbm: ["\\mathbb{#1}", 1],
            bordermatrix: ["\\matrix{#1}", 1]
        },
        processEscapes: false
    }
};
//]]>
</script>
<script type="text/javascript" id="MathJax-script" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-chtml.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">4.10.0</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d6/d00/tutorial_py_root.html">OpenCV-Python Tutorials</a></li><li class="navelem"><a class="el" href="../../db/d27/tutorial_py_table_of_contents_feature2d.html">Feature Detection and Description</a></li>  </ul>
</div>
</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">FAST Algorithm for Corner Detection</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md1217"></a>
Goal</h1>
<p>In this chapter,</p><ul>
<li>We will understand the basics of FAST algorithm</li>
<li>We will find corners using OpenCV functionalities for FAST algorithm.</li>
</ul>
<h1><a class="anchor" id="autotoc_md1218"></a>
Theory</h1>
<p>We saw several feature detectors and many of them are really good. But when looking from a real-time application point of view, they are not fast enough. One best example would be SLAM (Simultaneous Localization and Mapping) mobile robot which have limited computational resources.</p>
<p>As a solution to this, FAST (Features from Accelerated Segment Test) algorithm was proposed by Edward Rosten and Tom Drummond in their paper "Machine learning for high-speed corner detection" in 2006 (Later revised it in 2010). A basic summary of the algorithm is presented below. Refer original paper for more details (All the images are taken from original paper).</p>
<h2><a class="anchor" id="autotoc_md1219"></a>
Feature Detection using FAST</h2>
<ol type="1">
<li>Select a pixel \(p\) in the image which is to be identified as an interest point or not. Let its intensity be \(I_p\).</li>
<li>Select appropriate threshold value \(t\).</li>
<li>Consider a circle of 16 pixels around the pixel under test. (See the image below)</li>
</ol>
<div class="image">
<img src="../../fast_speedtest.jpg" alt=""/>
<div class="caption">
image</div></div>
    <ol type="1">
<li>Now the pixel \(p\) is a corner if there exists a set of \(n\) contiguous pixels in the circle (of 16 pixels) which are all brighter than \(I_p + t\), or all darker than \(I_p − t\). (Shown as white dash lines in the above image). \(n\) was chosen to be 12.</li>
<li>A <b>high-speed test</b> was proposed to exclude a large number of non-corners. This test examines only the four pixels at 1, 9, 5 and 13 (First 1 and 9 are tested if they are too brighter or darker. If so, then checks 5 and 13). If \(p\) is a corner, then at least three of these must all be brighter than \(I_p + t\) or darker than \(I_p − t\). If neither of these is the case, then \(p\) cannot be a corner. The full segment test criterion can then be applied to the passed candidates by examining all pixels in the circle. This detector in itself exhibits high performance, but there are several weaknesses:<ul>
<li>It does not reject as many candidates for n &lt; 12.</li>
<li>The choice of pixels is not optimal because its efficiency depends on ordering of the questions and distribution of corner appearances.</li>
<li>Results of high-speed tests are thrown away.</li>
<li>Multiple features are detected adjacent to one another.</li>
</ul>
</li>
</ol>
<p>First 3 points are addressed with a machine learning approach. Last one is addressed using non-maximal suppression.</p>
<h2><a class="anchor" id="autotoc_md1220"></a>
Machine Learning a Corner Detector</h2>
<ol type="1">
<li>Select a set of images for training (preferably from the target application domain)</li>
<li>Run FAST algorithm in every images to find feature points.</li>
<li>For every feature point, store the 16 pixels around it as a vector. Do it for all the images to get feature vector \(P\).</li>
<li>Each pixel (say \(x\)) in these 16 pixels can have one of the following three states:</li>
</ol>
<div class="image">
<img src="../../fast_eqns.jpg" alt=""/>
<div class="caption">
image</div></div>
    <ol type="1">
<li>Depending on these states, the feature vector \(P\) is subdivided into 3 subsets, \(P_d\), \(P_s\), \(P_b\).</li>
<li>Define a new boolean variable, \(K_p\), which is true if \(p\) is a corner and false otherwise.</li>
<li>Use the ID3 algorithm (decision tree classifier) to query each subset using the variable \(K_p\) for the knowledge about the true class. It selects the \(x\) which yields the most information about whether the candidate pixel is a corner, measured by the entropy of \(K_p\).</li>
<li>This is recursively applied to all the subsets until its entropy is zero.</li>
<li>The decision tree so created is used for fast detection in other images.</li>
</ol>
<h2><a class="anchor" id="autotoc_md1221"></a>
Non-maximal Suppression</h2>
<p>Detecting multiple interest points in adjacent locations is another problem. It is solved by using Non-maximum Suppression.</p>
<ol type="1">
<li>Compute a score function, \(V\) for all the detected feature points. \(V\) is the sum of absolute difference between \(p\) and 16 surrounding pixels values.</li>
<li>Consider two adjacent keypoints and compute their \(V\) values.</li>
<li>Discard the one with lower \(V\) value.</li>
</ol>
<h2><a class="anchor" id="autotoc_md1222"></a>
Summary</h2>
<p>It is several times faster than other existing corner detectors.</p>
<p>But it is not robust to high levels of noise. It is dependent on a threshold.</p>
<h1><a class="anchor" id="autotoc_md1223"></a>
FAST Feature Detector in OpenCV</h1>
<p>It is called as any other feature detector in OpenCV. If you want, you can specify the threshold, whether non-maximum suppression to be applied or not, the neighborhood to be used etc.</p>
<p>For the neighborhood, three flags are defined, cv.FAST_FEATURE_DETECTOR_TYPE_5_8, cv.FAST_FEATURE_DETECTOR_TYPE_7_12 and cv.FAST_FEATURE_DETECTOR_TYPE_9_16. Below is a simple code on how to detect and draw the FAST feature points. </p><div class="fragment"><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</div>
<div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div>
<div class="line"> </div>
<div class="line">img = <a class="code hl_function" href="../../d4/da8/group__imgcodecs.html#gab32ee19e22660912565f8140d0f675a8">cv.imread</a>(<span class="stringliteral">&#39;blox.jpg&#39;</span>, cv.IMREAD_GRAYSCALE) <span class="comment"># `&lt;opencv_root&gt;/samples/data/blox.jpg`</span></div>
<div class="line"> </div>
<div class="line"><span class="comment"># Initiate FAST object with default values</span></div>
<div class="line">fast = cv.FastFeatureDetector_create()</div>
<div class="line"> </div>
<div class="line"><span class="comment"># find and draw the keypoints</span></div>
<div class="line">kp = fast.detect(img,<span class="keywordtype">None</span>)</div>
<div class="line">img2 = <a class="code hl_function" href="../../d4/d5d/group__features2d__draw.html#ga5d2bafe8c1c45289bc3403a40fb88920">cv.drawKeypoints</a>(img, kp, <span class="keywordtype">None</span>, color=(255,0,0))</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Print all default params</span></div>
<div class="line">print( <span class="stringliteral">&quot;Threshold: {}&quot;</span>.format(fast.getThreshold()) )</div>
<div class="line">print( <span class="stringliteral">&quot;nonmaxSuppression:{}&quot;</span>.format(fast.getNonmaxSuppression()) )</div>
<div class="line">print( <span class="stringliteral">&quot;neighborhood: {}&quot;</span>.format(fast.getType()) )</div>
<div class="line">print( <span class="stringliteral">&quot;Total Keypoints with nonmaxSuppression: {}&quot;</span>.format(len(kp)) )</div>
<div class="line"> </div>
<div class="line"><a class="code hl_function" href="../../d4/da8/group__imgcodecs.html#ga8ac397bd09e48851665edbe12aa28f25">cv.imwrite</a>(<span class="stringliteral">&#39;fast_true.png&#39;</span>, img2)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Disable nonmaxSuppression</span></div>
<div class="line">fast.setNonmaxSuppression(0)</div>
<div class="line">kp = fast.detect(img, <span class="keywordtype">None</span>)</div>
<div class="line"> </div>
<div class="line">print( <span class="stringliteral">&quot;Total Keypoints without nonmaxSuppression: {}&quot;</span>.format(len(kp)) )</div>
<div class="line"> </div>
<div class="line">img3 = <a class="code hl_function" href="../../d4/d5d/group__features2d__draw.html#ga5d2bafe8c1c45289bc3403a40fb88920">cv.drawKeypoints</a>(img, kp, <span class="keywordtype">None</span>, color=(255,0,0))</div>
<div class="line"> </div>
<div class="line"><a class="code hl_function" href="../../d4/da8/group__imgcodecs.html#ga8ac397bd09e48851665edbe12aa28f25">cv.imwrite</a>(<span class="stringliteral">&#39;fast_false.png&#39;</span>, img3)</div>
<div class="ttc" id="agroup__features2d__draw_html_ga5d2bafe8c1c45289bc3403a40fb88920"><div class="ttname"><a href="../../d4/d5d/group__features2d__draw.html#ga5d2bafe8c1c45289bc3403a40fb88920">cv::drawKeypoints</a></div><div class="ttdeci">void drawKeypoints(InputArray image, const std::vector&lt; KeyPoint &gt; &amp;keypoints, InputOutputArray outImage, const Scalar &amp;color=Scalar::all(-1), DrawMatchesFlags flags=DrawMatchesFlags::DEFAULT)</div><div class="ttdoc">Draws keypoints.</div></div>
<div class="ttc" id="agroup__imgcodecs_html_ga8ac397bd09e48851665edbe12aa28f25"><div class="ttname"><a href="../../d4/da8/group__imgcodecs.html#ga8ac397bd09e48851665edbe12aa28f25">cv::imwrite</a></div><div class="ttdeci">CV_EXPORTS_W bool imwrite(const String &amp;filename, InputArray img, const std::vector&lt; int &gt; &amp;params=std::vector&lt; int &gt;())</div><div class="ttdoc">Saves an image to a specified file.</div></div>
<div class="ttc" id="agroup__imgcodecs_html_gab32ee19e22660912565f8140d0f675a8"><div class="ttname"><a href="../../d4/da8/group__imgcodecs.html#gab32ee19e22660912565f8140d0f675a8">cv::imread</a></div><div class="ttdeci">CV_EXPORTS_W Mat imread(const String &amp;filename, int flags=IMREAD_COLOR)</div><div class="ttdoc">Loads an image from a file.</div></div>
</div><!-- fragment --><p> See the results. First image shows FAST with nonmaxSuppression and second one without nonmaxSuppression:</p>
<div class="image">
<img src="../../fast_kp.jpg" alt=""/>
<div class="caption">
image</div></div>
    <h1><a class="anchor" id="autotoc_md1224"></a>
Additional Resources</h1>
<ol type="1">
<li>Edward Rosten and Tom Drummond, "Machine learning for high speed corner detection" in 9th European Conference on Computer Vision, vol. 1, 2006, pp. 430–443.</li>
<li>Edward Rosten, Reid Porter, and Tom Drummond, "Faster and better: a machine learning approach to
    corner detection" in IEEE Trans. Pattern Analysis and Machine Intelligence, 2010, vol 32, pp. 105-119.</li>
</ol>
<h1><a class="anchor" id="autotoc_md1225"></a>
Exercises</h1>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sun Jun 2 2024 21:52:14 for OpenCV by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.9.8
</small></address>
<script type="text/javascript">
//<![CDATA[
addTutorialsButtons();
//]]>
</script>
</body>
</html>
